setwd("C:/Users/eduar/Documents/GitHub/specialization_diversity_AF")
model_fits_df= read.table("4_quasse/1_24_model_fits_df.csv", sep=",", h = T)
model_fits_df
### AIC = -2(log-likelihood) + 2K
-2*model_fits_df$lnlik +2*(model_fits_df$n_par)
### AIC = -2(log-likelihood) + 2K
aic = -2*model_fits_df$lnlik +2*(model_fits_df$n_par)
### AIC - 2k(k+1) / (n-k-1)
aicc = aic (-2*(model_fits_df$n_par+1))/(66-model_fits_df$n_par-1)
### AIC = -2(log-likelihood) + 2K
aic = -2*model_fits_df$lnlik +2*(model_fits_df$n_par)
### AIC - 2k(k+1) / (n-k-1)
aicc = aic (-2*(model_fits_df$n_par+1))/(66-model_fits_df$n_par-1)
aic
aic
### AIC - 2k(k+1) / (n-k-1)
aicc = aic (-2*(model_fits_df$n_par+1))/(66-model_fits_df$n_par-1)
(66-model_fits_df$n_par-1)
-2*(model_fits_df$n_par+1)
-2*(model_fits_df$n_par+1)/(66-model_fits_df$n_par-1)
aic -2*(model_fits_df$n_par+1)/(66-model_fits_df$n_par-1)
### AIC - 2k(k+1) / (n-k-1)
aicc = aic -2*(model_fits_df$n_par+1)/(66-model_fits_df$n_par-1)
aicc
### organizing into data frame
data.frame(model_fits_df, aic, aicc)
### organizing into data frame
model_fits_df = data.frame(model_fits_df, aic, aicc)
1:3*1
model_fits_df[1:3*2]
model_fits_df[(1:3)*2]
(1:3)*2
seq(from=1, to=21, by=3)
seq(from=1, to=24, by=3)
model_fits_df
nrow(model_fits_df)
nrow(model_fits_df)/3
seq(from=1, to=24, by=3)
seq(from=1, to=23, by=3)
seq(from=1, to=25, by=3)
seq(from=1, to=19, by=3)
seq(from=1, to=22, by=3)
seq(from=1, to=24, by=3)
seq(from=1, to=26, by=3)
seq(from=1, to=24, by=3)
model_fits_df
best_fit_per_tree =c()
for (i in seq(from=1, to=24, by=3)){
one_tree = model_fits_df[i:(i+2),]
best_fit_per_tree = rbind(best_fit_per_tree, min(one_tree$aicc))
}
best_fit_per_tree
best_fit_per_tree =c()
for (i in seq(from=1, to=24, by=3)){
one_tree = model_fits_df[i:(i+2),]
best_fit_per_tree = rbind(best_fit_per_tree, one_tree[min(one_tree$aicc),] )
}
best_fit_per_tree
one_tree$aicc==min(one_tree$aicc)
best_fit_per_tree =c()
for (i in seq(from=1, to=24, by=3)){
one_tree = model_fits_df[i:(i+2),]
best_fit_per_tree = rbind(best_fit_per_tree, one_tree[one_tree$aicc==min(one_tree$aicc),] )
}
best_fit_per_tree
nrow(model_fits_df)
nrow(model_fits_df)-3
seq(from=1, to=69, by=3
seq(from=1, to=69, by=3)
nrow(model_fits_df)-2
final_set= nrow(model_fits_df)-2
seq(from=1, to=final_set, by=3)
best_fit_per_tree =c()
for (i in seq(from=1, to=final_set, by=3)){
one_tree = model_fits_df[i:(i+2),]
best_fit_per_tree = rbind(best_fit_per_tree, one_tree[one_tree$aicc==min(one_tree$aicc),] )
}
best_fit_per_tree
setwd("C:/Users/eduar/Documents/GitHub/specialization_diversity_AF")
library(ape)
library(diversitree)
library(FAmle)
### loading phylogenetic tree
mcc = read.tree("0_data/mcc_phylo.nwk")
phylo_trees = read.tree("0_data/100_rand_phylos.nwk")
### loading trait dataset
spp_hvolumes = read.table("1_hypervolume_inference/spp_hvolumes.csv", h=T, sep=",")
### setting trait vector
hvolumes = spp_hvolumes$hvolume
names(hvolumes) = spp_hvolumes$species
### loading iqr values
spp_iqr_env = read.table("1_hypervolume_inference/iqr_env_values", h=T, sep=",")
### loading iqr values
spp_iqr_env = read.table("1_hypervolume_inference/iqr_env_values.csv", h=T, sep=",")
setwd("C:/Users/eduar/Documents/GitHub/specialization_endemism_AF")
library(tidyverse)
library(PupillometryR)
library(ggpubr)
library(readr)
library(tidyr)
library(ggplot2)
library(Hmisc)
library(plyr)
library(RColorBrewer)
library(reshape2)
### iqr values
iqr_env_values = read.table("3_hypervolume_inference/iqr_env_values.csv", sep=",", h=T)
# scalling ph
iqr_env_values$soil_pH = iqr_env_values$soil_pH*10^-1
###loading spp geographic classification
spp_geographic_distribution = read.table("1_geographic_classification/spp_geographic_distribution.csv", sep=',', h=T)
# my colors
mycols = c( "#1E88E5", "#FFC107", "#D81B60")
one_env = data.frame(iqr_env_values, spp_geographic_distribution$state)
one_env
colnames(one_env)
colnames(one_env)[6] ="state"
ggplot(data= one_env, aes(x=solar_radiation, y=soil_pH, fill=state)) +
geom_point(aes(color=state),position = position_jitter(width = 0.07), size = 2, alpha = 0.65) +
scale_fill_manual(values=mycols)+
scale_colour_manual(values=mycols)+
theme(panel.background=element_rect(fill="white"), panel.grid=element_line(colour=NULL),panel.border=element_rect(fill=NA,colour="black"),axis.title=element_text(size=13,face="bold"),axis.text=element_text(size=6),legend.position = "none")
### setting trait vector
hvolumes = spp_hvolumes$hvolume
names(hvolumes) = spp_hvolumes$species
median(hvolumes)
median_value = median(hvolumes)
mean(hvolumes)
mean_value = mean(hvolumes)
spp_hvolumes
hvolumes < median_value
hvolumes[hvolumes < median_value]
setwd("C:/Users/eduar/Documents/GitHub/specialization_diversity_AF")
### loading trait dataset
spp_hvolumes = read.table("1_hypervolume_inference/spp_hvolumes.csv", h=T, sep=",")
names(hvolumes[hvolumes < median_value])
spp_geographic_distribution$species == names(hvolumes[hvolumes < median_value])
spp_geographic_distribution$species %in% names(hvolumes[hvolumes < median_value])
spp_geographic_distribution$state[spp_geographic_distribution$species %in% names(hvolumes[hvolumes < median_value])]
states = spp_geographic_distribution$state[spp_geographic_distribution$species %in% names(hvolumes[hvolumes < median_value])]
table(states)
specialists = spp_geographic_distribution$state[spp_geographic_distribution$species %in% names(hvolumes[hvolumes < median_value])]
specialists = names(hvolumes[hvolumes < median_value])]
generalists = names(hvolumes[hvolumes > median_value])]
specialists = names(hvolumes[hvolumes < median_value])
generalists = names(hvolumes[hvolumes > median_value])
generalists
spp_geographic_distribution$species %in% generalists
spp_geographic_distribution$state[spp_geographic_distribution$species %in% generalists]
table(spp_geographic_distribution$state[spp_geographic_distribution$species %in% generalists])
sister_geo_distance = read.table("3_sister_geography/sister_geo_distance.csv", sep=',', h=T)
sister_geo_distance
divergence = sister_geo_distance$divergence_time
names(divergence) = sister_geo_distance$species
divergence
divergence %in% specialists
specialists
names(divergence) %in% specialists
divergence[names(divergence) %in% specialists]
median(divergence[names(divergence) %in% specialists])
median(divergence[names(divergence) %in% gene])
median(divergence[names(divergence) %in% generalists])
ths_value = mean(hvolumes)
specialists = names(hvolumes[hvolumes < ths_value])
generalists = names(hvolumes[hvolumes > ths_value])
median(divergence[names(divergence) %in% specialists])
median(divergence[names(divergence) %in% generalists])
ths_value = 5
specialists = names(hvolumes[hvolumes < ths_value])
generalists = names(hvolumes[hvolumes > ths_value])
median(divergence[names(divergence) %in% specialists])
median(divergence[names(divergence) %in% generalists])
ths_value = 2.5
specialists = names(hvolumes[hvolumes < ths_value])
generalists = names(hvolumes[hvolumes > ths_value])
median(divergence[names(divergence) %in% specialists])
median(divergence[names(divergence) %in% generalists])
median(hvolumes)
mode(hvolumes)
hist(hvolumes)
ths_value = 4
specialists = names(hvolumes[hvolumes < ths_value])
generalists = names(hvolumes[hvolumes > ths_value])
median(divergence[names(divergence) %in% specialists])
median(divergence[names(divergence) %in% generalists])
mean(hvolumes)
ths_value = 3.6
specialists = names(hvolumes[hvolumes < ths_value])
generalists = names(hvolumes[hvolumes > ths_value])
median(divergence[names(divergence) %in% specialists])
median(divergence[names(divergence) %in% generalists])
median(hvolumes)
plot(hvolumes)
abline(v=median(hvolumes))
hist(hvolumes)
abline(v=median(hvolumes))
plot(hvolumes)
abline(h=median(hvolumes))
ths_value = median(hvolumes)
specialists = names(hvolumes[hvolumes < ths_value])
generalists = names(hvolumes[hvolumes > ths_value])
median(divergence[names(divergence) %in% specialists])
median(divergence[names(divergence) %in% generalists])
mean(divergence[names(divergence) %in% specialists])
mean(divergence[names(divergence) %in% generalists])
plot(density(hvolumes))
abline(v=median(hvolumes))
### setting discrete categories
hvolumes = spp_hvolumes$hvolume
names(hvolumes) = spp_hvolumes$species
# threshold
ths_value = median(hvolumes)
### setting discrete categories
ths_value = median(spp_hvolumes$)
### setting discrete categories
ths_value = median(spp_hvolumes$hvolume)
spp_hvolume_state = spp_hvolumes$hvolume
spp_hvolume_state = spp_hvolumes
spp_states = spp_hvolumes
spp_states$
specialists = names(hvolumes[hvolumes < ths_value])
spp_states$hvolume > ths_value
spp_states$hvolume[spp_states$hvolume > ths_value]
spp_states$hvolume[spp_states$hvolume < ths_value] = "specialist"
spp_states$hvolume[spp_states$hvolume > ths_value] = "generalist"
spp_states
### setting discrete categories
ths_value = median(spp_hvolumes$hvolume)
spp_states = spp_hvolumes
spp_states$hvolume[spp_states$hvolume < ths_value] = "specialist"
spp_states$hvolume[spp_states$hvolume > ths_value] = "generalist"
spp_states
### setting discrete categories
ths_value = median(spp_hvolumes$hvolume)
ths_value
### setting discrete categories
ths_value = median(spp_hvolumes$hvolume)
spp_states = spp_hvolumes
spp_states$hvolume
spp_states$hvolume[spp_states$hvolume < ths_value]
spp_states$hvolume[spp_states$hvolume < ths_value] = "specialist"
spp_states
spp_states$hvolume[spp_states$hvolume != "specialist"] = "generalist"
spp_states
p <-  starting.point.bisse(mcc)
p
states = spp_states$hvolume
names(states) = spp_states$species
states
bisse  <-  make.bisse(mcc,  states)
### setting discrete categories
ths_value = median(spp_hvolumes$hvolume)
states = spp_hvolumes$hvolume
### setting discrete categories
ths_value = median(spp_hvolumes$hvolume)
states = spp_hvolumes$hvolume
states[spp_hvolumes$hvolume < ths_value] = 1 #specialist
states[spp_hvolumes$hvolume > ths_value] = 0 #generalist
states
names(states) = spp_hvolumes$species
bisse  <-  make.bisse(mcc,  states)
start_params <-  starting.point.bisse(mcc)
### bisse
start_params <-  starting.point.bisse(mcc)
bisse  <-  make.bisse(mcc,  states)
bisse_mle = find.mle(bisse, start_params)
bisse_mle
bisse_mle$par
bisse  <-  constrain(bisse,  mu0  ~  mu1)
bisse_mle = find.mle(bisse, start_params)
bisse_mle$par
bisse_l_const  <-  constrain(bisse,  lambda0  ~  lambda1)
bisse_m_const  <-  constrain(bisse,  mu0  ~  mu1)
### bisse
start_params = starting.point.bisse(mcc)
bisse_full = make.bisse(mcc,  states)
bisse_l_const  <-  constrain(bisse_full,  lambda0  ~  lambda1)
bisse_m_const  <-  constrain(bisse_full,  mu0  ~  mu1)
### bisse
start_params = starting.point.bisse(mcc)
bisse_full = make.bisse(mcc,  states)
bisse_l_const  <-  constrain(bisse_full,  lambda0  ~  lambda1)
bisse_m_const  <-  constrain(bisse_full,  mu0  ~  mu1)
bisse_q_const  <-  constrain(bisse_full,  q01  ~  q10)
mle_full = find.mle(bisse_full, start_params)
mle_l_const = find.mle(bisse_l_const, start_params)
mle_m_const = find.mle(bisse_m_const, start_params)
mle_q_const = find.mle(bisse_q_const, start_params)
anova(mle_full, mle_l_const, mle_m_const, mle_q_const)
anova(mle_full, mle_l_const, mle_m_const)
bisse_full = make.bisse(mcc,  states)
bisse_m_const  =  constrain(bisse_full,  mu0  ~  mu1)
bisse_lm_const = constrain(bisse_full,  lambda0  ~  lambda1, mu0  ~  mu1)
mle_lm_const = find.mle(bisse_lm_const, start_params)
anova(mle_full, mle_l_const, mle_lm_const)
bisse_full = make.bisse(mcc,  states)
bisse_m_const  =  constrain(bisse_full,  mu0  ~  mu1)
bisse_lm_const = constrain(bisse_full,  lambda0  ~  lambda1, mu0  ~  mu1)
mle_full = find.mle(bisse_full, start_params)
mle_m_const = find.mle(bisse_m_const, start_params)
mle_lm_const = find.mle(bisse_lm_const, start_params)
anova(mle_lm_const, mle_m_const, mle_full)
mle_lm_const
mle_m_const
anova(mle_lm_const, mle_m_const, mle_full)
plot(history.from.sim.discrete(mcc,  0:1),  mcc))
plot(history.from.sim.discrete(mcc,  0:1),  mcc)
### setting discrete categories
ths_value = 2 #median(spp_hvolumes$hvolume)
states = spp_hvolumes$hvolume
states[spp_hvolumes$hvolume < ths_value] = 1 #specialist
states[spp_hvolumes$hvolume > ths_value] = 0 #generalist
names(states) = spp_hvolumes$species
### bisse
start_params = starting.point.bisse(mcc)
start_params
bisse_full = make.bisse(mcc,  states)
bisse_m_const  =  constrain(bisse_full,  mu0  ~  mu1)
bisse_lm_const = constrain(bisse_full,  lambda0  ~  lambda1, mu0  ~  mu1)
mle_full = find.mle(bisse_full, start_params)
mle_m_const = find.mle(bisse_m_const, start_params)
mle_lm_const = find.mle(bisse_lm_const, start_params)
anova(mle_lm_const, mle_m_const, mle_full)
### setting discrete categories
ths_value = 5 #median(spp_hvolumes$hvolume)
states = spp_hvolumes$hvolume
states[spp_hvolumes$hvolume < ths_value] = 1 #specialist
states[spp_hvolumes$hvolume > ths_value] = 0 #generalist
names(states) = spp_hvolumes$species
states
bisse_full = make.bisse(mcc,  states)
bisse_m_const  =  constrain(bisse_full,  mu0  ~  mu1)
bisse_lm_const = constrain(bisse_full,  lambda0  ~  lambda1, mu0  ~  mu1)
mle_full = find.mle(bisse_full, start_params)
mle_m_const = find.mle(bisse_m_const, start_params)
mle_lm_const = find.mle(bisse_lm_const, start_params)
anova(mle_lm_const, mle_m_const, mle_full)
hist(hvolumes)
hist(hvolumes, breaks=20)
### setting discrete categories
ths_value = 1 #median(spp_hvolumes$hvolume)
states = spp_hvolumes$hvolume
states[spp_hvolumes$hvolume < ths_value] = 1 #specialist
states[spp_hvolumes$hvolume > ths_value] = 0 #generalist
names(states) = spp_hvolumes$species
### bisse
start_params = starting.point.bisse(mcc)
bisse_full = make.bisse(mcc,  states)
bisse_m_const  =  constrain(bisse_full,  mu0  ~  mu1)
bisse_lm_const = constrain(bisse_full,  lambda0  ~  lambda1, mu0  ~  mu1)
mle_full = find.mle(bisse_full, start_params)
mle_m_const = find.mle(bisse_m_const, start_params)
mle_lm_const = find.mle(bisse_lm_const, start_params)
anova(mle_lm_const, mle_m_const, mle_full)
table(states)
hist(iqr_env_values$solar_radiation)
hist(iqr_env_values$soil_pH)
plot(iqr_env_values$solar_radiation, iqr_env_values$soil_pH)
hist(hvolumes, breaks=20)
### setting discrete categories
ths_value = 2.5 #median(spp_hvolumes$hvolume)
states = spp_hvolumes$hvolume
states[spp_hvolumes$hvolume < ths_value] = 1 #specialist
states[spp_hvolumes$hvolume > ths_value] = 0 #generalist
names(states) = spp_hvolumes$species
### bisse
start_params = starting.point.bisse(mcc)
bisse_full = make.bisse(mcc,  states)
bisse_m_const  =  constrain(bisse_full,  mu0  ~  mu1)
bisse_lm_const = constrain(bisse_full,  lambda0  ~  lambda1, mu0  ~  mu1)
mle_full = find.mle(bisse_full, start_params)
mle_m_const = find.mle(bisse_m_const, start_params)
mle_lm_const = find.mle(bisse_lm_const, start_params)
anova(mle_lm_const, mle_m_const, mle_full)
mle_lm_const$par
bisse_zero = constrain(bisse_lm_const, q01 ~ q10)
mle_zero = find.mle(bisse_zero, start_params)
anova(mle_zero, mle_lm_const, mle_m_const, mle_full)
### loading trait dataset
spp_geographic_distribution = read.table("0_data/spp_geographic_distribution.csv", h=T, sep=",")
geo_states = spp_geographic_distribution$state
geo_states == "AFother"
geo_states[geo_states == "AFother"] = 0
geo_states[geo_states == "AF"] = 2
geo_states[geo_states == "other"] = 1
geo_states
names(geo_states) = spp_geographic_distribution$species
###
start_geoess = starting.point.geosse(tree, eps=0.5)
###
start_geoess = starting.point.geosse(mcc)
geoess_full = make.geosse(mcc, states=geo_states, sampling.f=0.9)
geo_states = as.numeric(geo_states)
geo_states
names(geo_states) = spp_geographic_distribution$species
geoess_full = make.geosse(mcc, states=geo_states, sampling.f=0.9)
###
start_geosse = starting.point.geosse(mcc)
###
start_geosse = starting.point.geosse(mcc)
geosse_full = make.geosse(mcc, states=geo_states, sampling.f=0.9)
mle_geosse_full = find.mle(geosse_full, start_geosse)
mle_geosse_full
### setting geoess states
geo_states = spp_geographic_distribution$state
geo_states[geo_states == "AFother"] = "AB"
geo_states[geo_states == "other"] = "B"
geo_states[geo_states == "AF"] = "A"
names(geo_states) = spp_geographic_distribution$species
geosse_full = make.geosse(mcc, states=geo_states, sampling.f=0.9)
geosse_x_const = const(geosse_full, xA ~ xB)
geosse_x_const = constrain(geosse_full, xA ~ xB)
geosse_sx_const = constrain(geosse_full, sA ~ sB ~ sAB, xA ~ xB)
geosse_sx_const = constrain(geosse_full, sA ~ sB, xA ~ xB)
mle_geosse_x_const = find.mle(geosse_x_const, start_geosse)
mle_geosse_sx_const = find.mle(geosse_sx_const, start_geosse)
anova(mle_geosse_sx_const, mle_geosse_x_const, mle_geosse_full)
geosse_full = make.geosse(mcc, states=geo_states, sampling.f=0.9)
geosse_x_const = constrain(geosse_full, xA ~ xB, sampling.f=0.9)
geosse_sx_const = constrain(geosse_full, sA ~ sB, xA ~ xB, sampling.f=0.9)
mle_geosse_full = find.mle(geosse_full, start_geosse)
mle_geosse_x_const = find.mle(geosse_x_const, start_geosse)
mle_geosse_sx_const = find.mle(geosse_sx_const, start_geosse)
anova(mle_geosse_sx_const, mle_geosse_x_const, mle_geosse_full)
setwd("C:/Users/eduar/Documents/GitHub/specialization_diversity_AF")
library(ape)
library(diversitree)
library(FAmle)
source("traitDependent_functions.R")
### setting geographic states
geo_states = spp_geographic_distribution$state
geo_states
geo_states[geo_states == "AFother"] = "other"
geo_states
names(geo_states) = spp_geographic_distribution$species
res <- FISSE.binary(mcc, geo_states)
library(phangorn)
res <- FISSE.binary(mcc, geo_states)
res <- FISSE.binary(phy=mcc, states=geo_states)
geo_states
### setting geographic states
geo_states = spp_geographic_distribution$state
### setting geographic states
geo_states = spp_geographic_distribution$state
geo_states[geo_states == "AFother"] = 0
geo_states[geo_states == "other"] = 0
geo_states[geo_states == "AF"] = 1
geo_states
geo_states = as.numeric(geo_states)
names(geo_states) = spp_geographic_distribution$species
res <- FISSE.binary(phy=mcc, states=geo_states)
res
source("traitDependent_functions.R")
res <- FISSE.binary(phy=mcc, states=geo_states)
source("traitDependent_functions.R")
res <- FISSE.binary(phy=mcc, states=geo_states, qratetype = "parsimony" )
res
pval_2tailed   <- min(res$pval, 1-res$pval)*2
pval_2tailed
### setting discrete categories
ths_value = 2.5 #median(spp_hvolumes$hvolume)
hv_states = spp_hvolumes$hvolume
hv_states[hv_states < ths_value] = "1" #specialist
hv_states[hv_states != "1"] = "0" #generalist
hv_states = as.numeric(hv_states)
### setting discrete categories
ths_value = 2.5 #median(spp_hvolumes$hvolume)
hv_states = spp_hvolumes$hvolume
hv_states[hv_states < ths_value] = "1" #specialist
hv_states[hv_states != "1"] = "0" #generalist
hv_states = as.numeric(hv_states)
names(hv_states) = spp_hvolumes$species
hv_states
res2 <- FISSE.binary(phy=mcc, states=hv_states, qratetype = "parsimony" )
res2
### setting discrete categories
ths_value = 1.5 #median(spp_hvolumes$hvolume)
hv_states = spp_hvolumes$hvolume
hv_states[hv_states < ths_value] = "1" #specialist
hv_states[hv_states != "1"] = "0" #generalist
hv_states = as.numeric(hv_states)
names(hv_states) = spp_hvolumes$species
res2 <- FISSE.binary(phy=mcc, states=hv_states, qratetype = "parsimony" )
res2
pval_2tailed   <- min(res2$pval, 1-res2$pval)*2
pval_2tailed
